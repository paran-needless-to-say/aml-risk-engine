"""
ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ

ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í—¬í¼ í•¨ìˆ˜ë“¤ê³¼ ë°ì´í„° ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import json
import yaml
import hashlib
import time
from typing import Dict, List, Any, Optional, Union, Tuple
from datetime import datetime, timezone
from pathlib import Path
import pandas as pd
import numpy as np
from dataclasses import dataclass


@dataclass
class ValidationResult:
    """ê²€ì¦ ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    is_valid: bool
    errors: List[str]
    warnings: List[str]


def validate_address(address: str) -> bool:
    """
    ì´ë”ë¦¬ì›€ ì£¼ì†Œ í˜•ì‹ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        address: ê²€ì¦í•  ì£¼ì†Œ
        
    Returns:
        ìœ íš¨í•œ ì£¼ì†Œì¸ì§€ ì—¬ë¶€
    """
    if not isinstance(address, str):
        return False
    
    # ê¸°ë³¸ í˜•ì‹ ê²€ì¦
    if not address.startswith('0x'):
        return False
    
    if len(address) != 42:  # 0x + 40ì
        return False
    
    # 16ì§„ìˆ˜ ë¬¸ìë§Œ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸
    try:
        int(address[2:], 16)
        return True
    except ValueError:
        return False


def validate_transaction(transaction: Dict[str, Any]) -> ValidationResult:
    """
    íŠ¸ëœì­ì…˜ ë°ì´í„°ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        transaction: ê²€ì¦í•  íŠ¸ëœì­ì…˜ ë°ì´í„°
        
    Returns:
        ê²€ì¦ ê²°ê³¼
    """
    errors = []
    warnings = []
    
    # í•„ìˆ˜ í•„ë“œ í™•ì¸
    required_fields = ['from', 'to', 'value']
    for field in required_fields:
        if field not in transaction:
            errors.append(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
        elif transaction[field] is None:
            errors.append(f"í•„ìˆ˜ í•„ë“œê°€ None: {field}")
    
    # ì£¼ì†Œ í˜•ì‹ ê²€ì¦
    if 'from' in transaction and transaction['from']:
        if not validate_address(transaction['from']):
            errors.append(f"ì˜ëª»ëœ from ì£¼ì†Œ í˜•ì‹: {transaction['from']}")
    
    if 'to' in transaction and transaction['to']:
        if not validate_address(transaction['to']):
            errors.append(f"ì˜ëª»ëœ to ì£¼ì†Œ í˜•ì‹: {transaction['to']}")
    
    # ê°’ ìœ íš¨ì„± ê²€ì¦
    if 'value' in transaction:
        try:
            value = float(transaction['value'])
            if value < 0:
                errors.append("ê±°ë˜ ê¸ˆì•¡ì€ ìŒìˆ˜ì¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        except (ValueError, TypeError):
            errors.append(f"ì˜ëª»ëœ value í˜•ì‹: {transaction['value']}")
    
    # ê°€ìŠ¤ ê´€ë ¨ í•„ë“œ ê²€ì¦
    if 'gas' in transaction and transaction['gas'] is not None:
        try:
            gas = float(transaction['gas'])
            if gas <= 0:
                warnings.append("ê°€ìŠ¤ í•œë„ê°€ 0 ì´í•˜ì…ë‹ˆë‹¤")
        except (ValueError, TypeError):
            warnings.append(f"ì˜ëª»ëœ gas í˜•ì‹: {transaction['gas']}")
    
    if 'gasPrice' in transaction and transaction['gasPrice'] is not None:
        try:
            gas_price = float(transaction['gasPrice'])
            if gas_price <= 0:
                warnings.append("ê°€ìŠ¤ ê°€ê²©ì´ 0 ì´í•˜ì…ë‹ˆë‹¤")
        except (ValueError, TypeError):
            warnings.append(f"ì˜ëª»ëœ gasPrice í˜•ì‹: {transaction['gasPrice']}")
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ ê²€ì¦
    if 'timestamp' in transaction and transaction['timestamp'] is not None:
        try:
            timestamp = int(transaction['timestamp'])
            # í•©ë¦¬ì ì¸ ë²”ìœ„ í™•ì¸ (2009ë…„ ì´í›„, í˜„ì¬ ì‹œê°„ ì´ì „)
            if timestamp < 1230768000:  # 2009-01-01
                warnings.append("íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ë„ˆë¬´ ì´ë¦…ë‹ˆë‹¤")
            elif timestamp > int(time.time()) + 3600:  # í˜„ì¬ ì‹œê°„ + 1ì‹œê°„
                warnings.append("íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ë¯¸ë˜ì…ë‹ˆë‹¤")
        except (ValueError, TypeError):
            warnings.append(f"ì˜ëª»ëœ timestamp í˜•ì‹: {transaction['timestamp']}")
    
    return ValidationResult(
        is_valid=len(errors) == 0,
        errors=errors,
        warnings=warnings
    )


def normalize_address(address: str) -> str:
    """
    ì£¼ì†Œë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤ (ì†Œë¬¸ì ë³€í™˜).
    
    Args:
        address: ì •ê·œí™”í•  ì£¼ì†Œ
        
    Returns:
        ì •ê·œí™”ëœ ì£¼ì†Œ
    """
    if not isinstance(address, str):
        return ""
    
    return address.lower().strip()


def calculate_transaction_hash(transaction: Dict[str, Any]) -> str:
    """
    íŠ¸ëœì­ì…˜ì˜ í•´ì‹œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        transaction: íŠ¸ëœì­ì…˜ ë°ì´í„°
        
    Returns:
        íŠ¸ëœì­ì…˜ í•´ì‹œ
    """
    # í•´ì‹œ ê³„ì‚°ì— ì‚¬ìš©í•  í•„ë“œë“¤
    hash_fields = ['from', 'to', 'value', 'gas', 'gasPrice', 'timestamp']
    
    # ì •ë ¬ëœ í•„ë“œê°’ë“¤ë¡œ ë¬¸ìì—´ ìƒì„±
    hash_data = []
    for field in hash_fields:
        if field in transaction:
            hash_data.append(f"{field}:{transaction[field]}")
    
    hash_string = "|".join(hash_data)
    
    # SHA-256 í•´ì‹œ ê³„ì‚°
    return hashlib.sha256(hash_string.encode()).hexdigest()


def convert_wei_to_ether(wei_value: Union[int, float, str]) -> float:
    """
    Weië¥¼ Etherë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        wei_value: Wei ë‹¨ìœ„ ê°’
        
    Returns:
        Ether ë‹¨ìœ„ ê°’
    """
    try:
        wei = float(wei_value)
        return wei / 1e18
    except (ValueError, TypeError):
        return 0.0


def convert_ether_to_wei(ether_value: Union[int, float, str]) -> int:
    """
    Etherë¥¼ Weië¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        ether_value: Ether ë‹¨ìœ„ ê°’
        
    Returns:
        Wei ë‹¨ìœ„ ê°’
    """
    try:
        ether = float(ether_value)
        return int(ether * 1e18)
    except (ValueError, TypeError):
        return 0


def format_timestamp(timestamp: Union[int, float], format_str: str = "%Y-%m-%d %H:%M:%S") -> str:
    """
    íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬ë§·ëœ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        timestamp: Unix íƒ€ì„ìŠ¤íƒ¬í”„
        format_str: ë‚ ì§œ í˜•ì‹ ë¬¸ìì—´
        
    Returns:
        í¬ë§·ëœ ë‚ ì§œ ë¬¸ìì—´
    """
    try:
        dt = datetime.fromtimestamp(timestamp, tz=timezone.utc)
        return dt.strftime(format_str)
    except (ValueError, TypeError, OSError):
        return "Invalid timestamp"


def load_config(config_path: str) -> Dict[str, Any]:
    """
    ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤ (YAML ë˜ëŠ” JSON).
    
    Args:
        config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    config_path = Path(config_path)
    
    if not config_path.exists():
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            if config_path.suffix.lower() in ['.yaml', '.yml']:
                return yaml.safe_load(f)
            elif config_path.suffix.lower() == '.json':
                return json.load(f)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {config_path.suffix}")
    except Exception as e:
        raise Exception(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")


def save_config(config: Dict[str, Any], config_path: str) -> None:
    """
    ì„¤ì •ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        config: ì €ì¥í•  ì„¤ì • ë”•ì…”ë„ˆë¦¬
        config_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
    """
    config_path = Path(config_path)
    config_path.parent.mkdir(parents=True, exist_ok=True)
    
    try:
        with open(config_path, 'w', encoding='utf-8') as f:
            if config_path.suffix.lower() in ['.yaml', '.yml']:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
            elif config_path.suffix.lower() == '.json':
                json.dump(config, f, indent=2, ensure_ascii=False)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {config_path.suffix}")
    except Exception as e:
        raise Exception(f"ì„¤ì • íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")


def batch_process_transactions(transactions: List[Dict[str, Any]], 
                              batch_size: int = 1000) -> List[List[Dict[str, Any]]]:
    """
    íŠ¸ëœì­ì…˜ë“¤ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    
    Args:
        transactions: íŠ¸ëœì­ì…˜ ë¦¬ìŠ¤íŠ¸
        batch_size: ë°°ì¹˜ í¬ê¸°
        
    Returns:
        ë°°ì¹˜ë³„ë¡œ ë‚˜ë‰œ íŠ¸ëœì­ì…˜ ë¦¬ìŠ¤íŠ¸ë“¤
    """
    batches = []
    for i in range(0, len(transactions), batch_size):
        batch = transactions[i:i + batch_size]
        batches.append(batch)
    return batches


def calculate_statistics(values: List[Union[int, float]]) -> Dict[str, float]:
    """
    ê°’ë“¤ì˜ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        values: ê°’ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        í†µê³„ ë”•ì…”ë„ˆë¦¬
    """
    if not values:
        return {
            'count': 0,
            'mean': 0.0,
            'median': 0.0,
            'std': 0.0,
            'min': 0.0,
            'max': 0.0,
            'q25': 0.0,
            'q75': 0.0
        }
    
    values = [float(v) for v in values if v is not None]
    
    if not values:
        return {
            'count': 0,
            'mean': 0.0,
            'median': 0.0,
            'std': 0.0,
            'min': 0.0,
            'max': 0.0,
            'q25': 0.0,
            'q75': 0.0
        }
    
    return {
        'count': len(values),
        'mean': np.mean(values),
        'median': np.median(values),
        'std': np.std(values),
        'min': np.min(values),
        'max': np.max(values),
        'q25': np.percentile(values, 25),
        'q75': np.percentile(values, 75)
    }


def detect_outliers(values: List[Union[int, float]], 
                   method: str = 'iqr', 
                   threshold: float = 1.5) -> Tuple[List[int], List[Union[int, float]]]:
    """
    ì´ìƒì¹˜ë¥¼ íƒì§€í•©ë‹ˆë‹¤.
    
    Args:
        values: ê°’ ë¦¬ìŠ¤íŠ¸
        method: íƒì§€ ë°©ë²• ('iqr', 'zscore')
        threshold: ì„ê³„ê°’
        
    Returns:
        (ì´ìƒì¹˜ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸, ì´ìƒì¹˜ ê°’ ë¦¬ìŠ¤íŠ¸)
    """
    if not values:
        return [], []
    
    values = np.array([float(v) for v in values if v is not None])
    
    if len(values) == 0:
        return [], []
    
    outlier_indices = []
    
    if method == 'iqr':
        q1 = np.percentile(values, 25)
        q3 = np.percentile(values, 75)
        iqr = q3 - q1
        
        lower_bound = q1 - threshold * iqr
        upper_bound = q3 + threshold * iqr
        
        outlier_indices = np.where((values < lower_bound) | (values > upper_bound))[0].tolist()
        
    elif method == 'zscore':
        mean = np.mean(values)
        std = np.std(values)
        
        if std > 0:
            z_scores = np.abs((values - mean) / std)
            outlier_indices = np.where(z_scores > threshold)[0].tolist()
    
    outlier_values = [values[i] for i in outlier_indices]
    
    return outlier_indices, outlier_values


def create_summary_report(transactions: List[Dict[str, Any]], 
                         address: str,
                         features: Dict[str, float],
                         risk_score: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        transactions: íŠ¸ëœì­ì…˜ ë¦¬ìŠ¤íŠ¸
        address: ë¶„ì„ ëŒ€ìƒ ì£¼ì†Œ
        features: ì¶”ì¶œëœ í”¼ì²˜ë“¤
        risk_score: ë¦¬ìŠ¤í¬ ìŠ¤ì½”ì–´ ê²°ê³¼
        
    Returns:
        ìš”ì•½ ë³´ê³ ì„œ ë”•ì…”ë„ˆë¦¬
    """
    # íŠ¸ëœì­ì…˜ í†µê³„
    values = [float(tx.get('value', 0)) for tx in transactions]
    value_stats = calculate_statistics(values)
    
    # ì‹œê°„ ë¶„ì„
    timestamps = [tx.get('timestamp') for tx in transactions if tx.get('timestamp')]
    time_range = {
        'start': format_timestamp(min(timestamps)) if timestamps else "N/A",
        'end': format_timestamp(max(timestamps)) if timestamps else "N/A",
        'duration_hours': (max(timestamps) - min(timestamps)) / 3600 if len(timestamps) >= 2 else 0
    }
    
    # ì£¼ì†Œ ë¶„ì„
    counterparties = set()
    for tx in transactions:
        from_addr = normalize_address(tx.get('from', ''))
        to_addr = normalize_address(tx.get('to', ''))
        target_addr = normalize_address(address)
        
        if from_addr == target_addr and to_addr:
            counterparties.add(to_addr)
        elif to_addr == target_addr and from_addr:
            counterparties.add(from_addr)
    
    return {
        'analysis_summary': {
            'target_address': normalize_address(address),
            'analysis_timestamp': datetime.now(timezone.utc).isoformat(),
            'transaction_count': len(transactions),
            'unique_counterparties': len(counterparties),
            'time_range': time_range
        },
        'transaction_statistics': {
            'value_stats': value_stats,
            'total_volume': sum(values),
            'average_value': value_stats['mean'],
            'largest_transaction': value_stats['max']
        },
        'risk_assessment': {
            'risk_score': risk_score.get('risk_score', 0.0),
            'risk_level': risk_score.get('risk_level', 'UNKNOWN'),
            'confidence': 'HIGH' if len(transactions) >= 10 else 'LOW'
        },
        'key_features': {
            'transaction_frequency': features.get('centrality_tx_frequency', 0),
            'unique_addresses': features.get('centrality_unique_addresses', 0),
            'total_exposure': features.get('exposure_total_value', 0),
            'behavioral_score': features.get('behavior_repeat_tx_ratio', 0)
        },
        'alerts': _generate_alerts(features, risk_score),
        'recommendations': _generate_recommendations(risk_score)
    }


def _generate_alerts(features: Dict[str, float], risk_score: Dict[str, Any]) -> List[str]:
    """ê²½ê³  ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    alerts = []
    
    if risk_score.get('risk_level') == 'HIGH':
        alerts.append("ğŸš¨ ë†’ì€ ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ì´ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    if features.get('centrality_tx_frequency', 0) > 100:
        alerts.append("âš ï¸ ê³ ë¹ˆë„ ê±°ë˜ íŒ¨í„´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    if features.get('exposure_max_tx_value', 0) > 1000000:
        alerts.append("ğŸ’° ëŒ€ì•¡ ê±°ë˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    if features.get('centrality_unique_addresses', 0) > 50:
        alerts.append("ğŸ”— ë‹¤ìˆ˜ì˜ ì£¼ì†Œì™€ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
    
    return alerts


def _generate_recommendations(risk_score: Dict[str, Any]) -> List[str]:
    """ê¶Œì¥ì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    recommendations = []
    
    risk_level = risk_score.get('risk_level', 'UNKNOWN')
    
    if risk_level == 'HIGH':
        recommendations.extend([
            "ì¶”ê°€ ì¡°ì‚¬ê°€ í•„ìš”í•©ë‹ˆë‹¤",
            "ê´€ë ¨ ê±°ë˜ ë‚´ì—­ì„ ìƒì„¸íˆ ê²€í† í•˜ì„¸ìš”",
            "ê·œì œ ë‹¹êµ­ì— ë³´ê³ ë¥¼ ê³ ë ¤í•˜ì„¸ìš”"
        ])
    elif risk_level == 'MEDIUM':
        recommendations.extend([
            "ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤",
            "ê±°ë˜ íŒ¨í„´ ë³€í™”ë¥¼ ì£¼ì‹œí•˜ì„¸ìš”"
        ])
    elif risk_level == 'LOW':
        recommendations.append("ì •ìƒì ì¸ ê±°ë˜ íŒ¨í„´ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤")
    
    return recommendations


def load_excel_data(file_path: str, sheet_name: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    Excel íŒŒì¼ì—ì„œ íŠ¸ëœì­ì…˜ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        file_path: Excel íŒŒì¼ ê²½ë¡œ
        sheet_name: ì‹œíŠ¸ëª… (Noneì´ë©´ ì²« ë²ˆì§¸ ì‹œíŠ¸)
    
    Returns:
        íŠ¸ëœì­ì…˜ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    try:
        # Excel íŒŒì¼ ì½ê¸°
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        
        # ì»¬ëŸ¼ëª…ì„ ì†Œë¬¸ìë¡œ ë³€í™˜ ë° ê³µë°± ì œê±°
        df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')
        
        # NaN ê°’ ì²˜ë¦¬
        df = df.fillna('')
        
        # ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        transactions = df.to_dict('records')
        
        return transactions
        
    except Exception as e:
        raise Exception(f"Excel íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")


def convert_excel_to_standard_format(transactions: List[Dict[str, Any]], 
                                   column_mapping: Optional[Dict[str, str]] = None) -> List[Dict[str, Any]]:
    """
    Excelì—ì„œ ë¡œë“œí•œ ë°ì´í„°ë¥¼ í‘œì¤€ íŠ¸ëœì­ì…˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        transactions: Excelì—ì„œ ë¡œë“œí•œ ì›ë³¸ ë°ì´í„°
        column_mapping: ì»¬ëŸ¼ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ {'excel_column': 'standard_column'}
    
    Returns:
        í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœ íŠ¸ëœì­ì…˜ ë¦¬ìŠ¤íŠ¸
    """
    # ê¸°ë³¸ ì»¬ëŸ¼ ë§¤í•‘
    default_mapping = {
        'from': 'from',
        'from_address': 'from',
        'sender': 'from',
        'to': 'to', 
        'to_address': 'to',
        'receiver': 'to',
        'recipient': 'to',
        'value': 'value',
        'amount': 'value',
        'eth_value': 'value',
        'timestamp': 'timestamp',
        'time': 'timestamp',
        'date': 'timestamp',
        'gas': 'gas',
        'gas_limit': 'gas',
        'gas_price': 'gasPrice',
        'gasprice': 'gasPrice',
        'hash': 'hash',
        'tx_hash': 'hash',
        'transaction_hash': 'hash',
        'block_number': 'blockNumber',
        'block': 'blockNumber'
    }
    
    # ì‚¬ìš©ì ë§¤í•‘ì´ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
    if column_mapping:
        default_mapping.update(column_mapping)
    
    converted_transactions = []
    
    for tx in transactions:
        converted_tx = {}
        
        # ì»¬ëŸ¼ ë§¤í•‘ ì ìš©
        for excel_col, standard_col in default_mapping.items():
            if excel_col in tx:
                value = tx[excel_col]
                
                # ë°ì´í„° íƒ€ì… ë³€í™˜
                if standard_col in ['value', 'gas', 'gasPrice']:
                    try:
                        converted_tx[standard_col] = float(value) if value else 0.0
                    except (ValueError, TypeError):
                        converted_tx[standard_col] = 0.0
                        
                elif standard_col in ['timestamp', 'blockNumber']:
                    try:
                        if isinstance(value, str) and value:
                            # ë‚ ì§œ ë¬¸ìì—´ì¸ ê²½ìš° íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ë³€í™˜
                            if '-' in str(value) or '/' in str(value):
                                dt = pd.to_datetime(value)
                                converted_tx[standard_col] = int(dt.timestamp())
                            else:
                                converted_tx[standard_col] = int(float(value))
                        else:
                            converted_tx[standard_col] = int(float(value)) if value else 0
                    except (ValueError, TypeError):
                        converted_tx[standard_col] = 0
                        
                else:
                    # ë¬¸ìì—´ í•„ë“œ (ì£¼ì†Œ, í•´ì‹œ ë“±)
                    converted_tx[standard_col] = str(value).strip() if value else ""
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if converted_tx.get('from') and converted_tx.get('to'):
            converted_transactions.append(converted_tx)
    
    return converted_transactions


def save_processed_data(transactions: List[Dict[str, Any]], 
                       output_path: str, 
                       format: str = 'jsonl') -> None:
    """
    ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        transactions: ì €ì¥í•  íŠ¸ëœì­ì…˜ ë°ì´í„°
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        format: ì €ì¥ í˜•ì‹ ('jsonl', 'json', 'csv')
    """
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    try:
        if format == 'jsonl':
            import jsonlines
            with jsonlines.open(output_path, mode='w') as writer:
                for tx in transactions:
                    writer.write(tx)
                    
        elif format == 'json':
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(transactions, f, indent=2, ensure_ascii=False)
                
        elif format == 'csv':
            df = pd.DataFrame(transactions)
            df.to_csv(output_path, index=False)
            
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {format}")
            
        print(f"ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
        
    except Exception as e:
        raise Exception(f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")


def preview_excel_data(file_path: str, sheet_name: Optional[str] = None, n_rows: int = 5) -> None:
    """
    Excel íŒŒì¼ì˜ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ë³´ê¸°í•©ë‹ˆë‹¤.
    
    Args:
        file_path: Excel íŒŒì¼ ê²½ë¡œ
        sheet_name: ì‹œíŠ¸ëª…
        n_rows: í‘œì‹œí•  í–‰ ìˆ˜
    """
    try:
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        
        print(f"ğŸ“Š Excel íŒŒì¼ ì •ë³´: {file_path}")
        print(f"ğŸ“ ë°ì´í„° í¬ê¸°: {df.shape[0]}í–‰ x {df.shape[1]}ì—´")
        print(f"ğŸ“‹ ì»¬ëŸ¼ëª…: {list(df.columns)}")
        print(f"\nğŸ“– ìƒìœ„ {n_rows}í–‰ ë¯¸ë¦¬ë³´ê¸°:")
        print(df.head(n_rows).to_string())
        
        # ê²°ì¸¡ê°’ í™•ì¸
        missing = df.isnull().sum()
        if missing.sum() > 0:
            print(f"\nâš ï¸  ê²°ì¸¡ê°’:")
            for col, count in missing.items():
                if count > 0:
                    print(f"  {col}: {count}ê°œ")
    
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {e}")
